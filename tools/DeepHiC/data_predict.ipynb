{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import models.deephic as deephic\n",
    "\n",
    "from utils.io import spreadM, together\n",
    "\n",
    "from all_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(data, batch_size=64):\n",
    "    inputs = torch.tensor(data['data'], dtype=torch.float)\n",
    "    inds = torch.tensor(data['inds'], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(inputs, inds)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "\n",
    "#提取信息\n",
    "def data_info(data):\n",
    "    indices = data['inds']\n",
    "    compacts = data['compacts'][()]\n",
    "    sizes = data['sizes'][()]\n",
    "    return indices, compacts, sizes\n",
    "\n",
    "get_digit = lambda x: int(''.join(list(filter(str.isdigit, x))))\n",
    "\n",
    "def filename_parser(filename):\n",
    "    info_str = filename.split('.')[0].split('_')[2:-1]\n",
    "    chunk = get_digit(info_str[0])\n",
    "    stride = get_digit(info_str[1])\n",
    "    bound = get_digit(info_str[2])\n",
    "    scale = 1 if info_str[3] == 'nonpool' else get_digit(info_str[3])\n",
    "    return chunk, stride, bound, scale\n",
    "\n",
    "#TODO:好好研究一下这个\n",
    "def deephic_predictor(deephic_loader, ckpt_file, scale, res_num, device):\n",
    "    #加载模型\n",
    "    #只用Generator\n",
    "    deepmodel = deephic.Generator(scale_factor=scale, in_channel=1, resblock_num=res_num).to(device)\n",
    "    if not os.path.isfile(ckpt_file):\n",
    "        ckpt_file = f'save/{ckpt_file}'\n",
    "    \n",
    "    #加载训练好的权重\n",
    "    deepmodel.load_state_dict(torch.load(ckpt_file, map_location=device))\n",
    "\n",
    "\n",
    "    print(f'Loading DeepHiC checkpoint file from \"{ckpt_file}\"')\n",
    "    result_data = []\n",
    "    result_inds = []\n",
    "    deepmodel.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(deephic_loader, desc='DeepHiC Predicting: '):\n",
    "            lr, inds = batch\n",
    "            lr = lr.to(device) #shape:[64, 1, 40, 40]\n",
    "            out = deepmodel(lr) #[64, 1, 40, 40]\n",
    "            result_data.append(out.to('cpu').numpy())\n",
    "            result_inds.append(inds.numpy())\n",
    "    \n",
    "    #拼接\n",
    "    result_data = np.concatenate(result_data, axis=0)#(76090, 1, 40, 40)\n",
    "    result_inds = np.concatenate(result_inds, axis=0)#(76090,4)\n",
    "    print(\"result_data shape\",result_data.shape)\n",
    "    print(\"result_inds shape\",result_inds.shape)\n",
    "\n",
    "\n",
    "    deep_hics = together(result_data, result_inds, tag='Reconstructing: ')\n",
    "    #返回的是字典\n",
    "    return deep_hics\n",
    "\n",
    "\n",
    "\n",
    "def save_data(deep_hic, compact, size, file):\n",
    "    #TODO:关键是这里\n",
    "    deephic = spreadM(deep_hic, compact, size, convert_int=False, verbose=True)\n",
    "    np.savez_compressed(file, deephic=deephic, compact=compact)\n",
    "    print('Saving file:', file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Predict process needs large memory, thus ensure that your machine have ~150G memory.\n"
     ]
    }
   ],
   "source": [
    "# python data_predict.py -lr 40kb -ckpt save/generator_nonpool_deephic.pytorch -c GM12878\n",
    "cell_line = \"GM12878\"\n",
    "low_res = \"40kb\"\n",
    "\n",
    "#这里是可以改的\n",
    "ckpt_file = \"save/deephic_raw_16.pth\"\n",
    "res_num = 5\n",
    "# cuda = args.cuda\n",
    "print('WARNING: Predict process needs large memory, thus ensure that your machine have ~150G memory.')\n",
    "if multiprocessing.cpu_count() > 23:\n",
    "    pool_num = 23\n",
    "else:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = os.path.join(root_dir, 'data')\n",
    "out_dir = os.path.join(root_dir, 'predict', cell_line)\n",
    "mkdir(out_dir)\n",
    "\n",
    "files = [f for f in os.listdir(in_dir) if f.find(low_res) >= 0]\n",
    "deephic_file = [f for f in files if f.find(cell_line.lower()+'.npz') >= 0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deephic_10kb40kb_c40_s40_b201_nonpool_gm12878.npz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deephic_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "chunk, stride, bound, scale = filename_parser(deephic_file)\n",
    "\n",
    "device = torch.device(f'cuda:{cuda}' if (torch.cuda.is_available() and cuda>-1 and cuda<torch.cuda.device_count()) else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data[DeepHiC]: deephic_10kb40kb_c40_s40_b201_nonpool_gm12878.npz\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f'Loading data[DeepHiC]: {deephic_file}')\n",
    "deephic_data = np.load(os.path.join(in_dir, deephic_file), allow_pickle=True)\n",
    "deephic_loader = dataloader(deephic_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, compacts, sizes = data_info(deephic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepHiC checkpoint file from \"save/deephic_raw_16.pth\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepHiC Predicting: 100%|██████████| 1189/1189 [05:42<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_data shape (76090, 1, 40, 40)\n",
      "result_inds shape (76090, 4)\n",
      "Reconstructing:  data contain [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 'X'] chromosomes\n"
     ]
    }
   ],
   "source": [
    "#deephic_loader里是40*40的，返回的是完整的了\n",
    "deep_hics = deephic_predictor(deephic_loader, ckpt_file, scale, res_num, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "  File \"/share/home/mliu/anaconda3/envs/sv/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'save_data_n' on <module '__main__'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start a multiprocess pool with process_num = 23 for saving predicted data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pool = multiprocessing.Pool(processes=pool_num)\n",
    "print(f'Start a multiprocess pool with process_num = {pool_num} for saving predicted data')\n",
    "\n",
    "def save_data_n(key):\n",
    "    file = os.path.join(out_dir, f'predict_chr{key}_{low_res}.npz')\n",
    "    save_data(deep_hics[key], compacts[key], sizes[key], file)\n",
    "\n",
    "\n",
    "for key in compacts.keys():\n",
    "    pool.apply_async(save_data_n, (key,))\n",
    "\n",
    "    \n",
    "pool.close()\n",
    "pool.join()\n",
    "print(f'All data saved. Running cost is {(time.time()-start)/60:.1f} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/share/home/mliu/sc_sv/imputation/DeepHiC/data/RaoHiC/predict/GM12878/predict_chr1_40kb.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
