{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from utils.io import compactM, spreadM, downsampling\n",
    "from all_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python data_generate.py -hr 10kb -lr 40kb -s all -chunk 40 -stride 40 -bound 201 -scale 1 -c GM12878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cell_line = \"GM12878\"\n",
    "high_res = \"10kb\"\n",
    "low_res = \"40kb\"\n",
    "ratio = 16 #默认16\n",
    "\n",
    "pool_num = 23 if multiprocessing.cpu_count() > 23 else multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, 'mat', cell_line)\n",
    "in_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.find(high_res) >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 40kb files from 10kb files by 16x downsampling.\n"
     ]
    }
   ],
   "source": [
    "print(f'Generating {low_res} files from {high_res} files by {ratio}x downsampling.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(in_file, low_res, ratio):\n",
    "    data = np.load(in_file)\n",
    "    hic = data['hic'] #数据\n",
    "    compact_idx = data['compact']\n",
    "\n",
    "    down_hic = downsampling(hic, ratio)\n",
    "\n",
    "    chr_name = os.path.basename(in_file).split('_')[0]\n",
    "\n",
    "    out_file = os.path.join(os.path.dirname(in_file), f'{chr_name}_{low_res}.npz')\n",
    "\n",
    "    np.savez_compressed(out_file, hic=down_hic, compact=compact_idx, ratio=ratio)\n",
    "    print('Saving file:', out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40kb\n",
      "16\n",
      "Saving file: data/RaoHiC/mat/GM12878/chr18_40kb.npz\n"
     ]
    }
   ],
   "source": [
    "file = \"data/RaoHiC/mat/GM12878/chr18_10kb.npz\"\n",
    "print(low_res)\n",
    "print(ratio)\n",
    "downsample(file, low_res, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start a multiprocess pool with process_num = 23\n",
      "Saving file: data/RaoHiC/mat/GM12878/chr18_40kb.npz\n",
      "All downsampling processes done. Running cost is 0.3 min.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f'Start a multiprocess pool with process_num = {pool_num}')\n",
    "pool = multiprocessing.Pool(pool_num)\n",
    "\n",
    "for file in in_files:\n",
    "    pool.apply_async(downsample, (file, low_res, ratio))\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(f'All downsampling processes done. Running cost is {(time.time()-start)/60:.1f} min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
